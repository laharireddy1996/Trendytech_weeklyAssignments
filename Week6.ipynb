{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06ba5568",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import getpass\n",
    "username = getpass.getuser()\n",
    "spark = SparkSession. \\\n",
    "builder. \\\n",
    "config('spark.ui.port','0'). \\\n",
    "config(\"spark.sql.warehouse.dir\",f\"/user/itv016269/warehouse\"). \\\n",
    "enableHiveSupport(). \\\n",
    "master('yarn'). \\\n",
    "getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "571ace13",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_list = [(\"Spring\",12.3),(\"Summer\",10.5),(\"Autumn\",8.2),(\"Winter\",15.1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4027315",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_schema = \"season string, windspeed float\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6bb3ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = spark.createDataFrame(sample_list,list_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8641aae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+\n",
      "|season|windspeed|\n",
      "+------+---------+\n",
      "|Spring|     12.3|\n",
      "|Summer|     10.5|\n",
      "|Autumn|      8.2|\n",
      "|Winter|     15.1|\n",
      "+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb7d1ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "library_schema=StructType([StructField(\"library_name\", StringType()),\n",
    "                           StructField(\"location\",StringType()),\n",
    "                           StructField(\"books\",ArrayType(StructType([\n",
    "                               StructField(\"bookid\",StringType()),\n",
    "                               StructField(\"book_name\",StringType()),\n",
    "                               StructField(\"author_name\",StringType()),\n",
    "                               StructField(\"copies_available\",IntegerType())\n",
    "                           ]))),\n",
    "                           StructField(\"members\",ArrayType(StructType([\n",
    "                               StructField(\"member_id\",StringType()),\n",
    "                               StructField(\"member_name\",StringType()),\n",
    "                               StructField(\"age\",IntegerType()),\n",
    "                               StructField(\"books_borrowed\",StringType())\n",
    "                           ]))),\n",
    "                                       ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85ce663c",
   "metadata": {},
   "outputs": [],
   "source": [
    "library_df=spark.read \\\n",
    ".format('json') \\\n",
    ".option(\"header\",\"true\") \\\n",
    ".schema(library_schema) \\\n",
    ".load(\"/public/trendytech/datasets/library_data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ecf1068e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------+--------------------+--------------------+\n",
      "|     library_name|   location|               books|             members|\n",
      "+-----------------+-----------+--------------------+--------------------+\n",
      "|  Central Library|City Center|[{null, The Great...|[{M001, John Smit...|\n",
      "|Community Library|     Suburb|[{null, 1984, nul...|[{M003, Michael B...|\n",
      "+-----------------+-----------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "672ef206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- library_name: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- books: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- bookid: string (nullable = true)\n",
      " |    |    |-- book_name: string (nullable = true)\n",
      " |    |    |-- author_name: string (nullable = true)\n",
      " |    |    |-- copies_available: integer (nullable = true)\n",
      " |-- members: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- member_id: string (nullable = true)\n",
      " |    |    |-- member_name: string (nullable = true)\n",
      " |    |    |-- age: integer (nullable = true)\n",
      " |    |    |-- books_borrowed: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45605def",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=spark.read \\\n",
    ".format(\"csv\") \\\n",
    ".option(\"header\",\"true\") \\\n",
    ".load(\"/public/trendytech/datasets/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5bc51699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+---------------+--------------+---+-------------+-----------+\n",
      "|train_number|train_name|seats_available|passenger_name|age|ticket_number|seat_number|\n",
      "+------------+----------+---------------+--------------+---+-------------+-----------+\n",
      "|         123|   Express|            100|          John| 25|         T123|         A1|\n",
      "|         123|   Express|            100|          Emma| 30|         T124|         B2|\n",
      "|         456| Superfast|            150|       Michael| 35|         T125|         C3|\n",
      "|         456| Superfast|            150|        Sophia| 40|         T126|         D4|\n",
      "|         789|     Local|             50|       William| 28|         T127|         E5|\n",
      "|         789|     Local|             50|        Sophia| 32|         T128|         F6|\n",
      "|         789|     Local|             50|        Oliver| 45|         T129|         G7|\n",
      "+------------+----------+---------------+--------------+---+-------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af64db86",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_df=train_df.drop(\"Passenger_name\",\"age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a29d74e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+---------------+-------------+-----------+\n",
      "|train_number|train_name|seats_available|ticket_number|seat_number|\n",
      "+------------+----------+---------------+-------------+-----------+\n",
      "|         123|   Express|            100|         T123|         A1|\n",
      "|         123|   Express|            100|         T124|         B2|\n",
      "|         456| Superfast|            150|         T125|         C3|\n",
      "|         456| Superfast|            150|         T126|         D4|\n",
      "|         789|     Local|             50|         T127|         E5|\n",
      "|         789|     Local|             50|         T128|         F6|\n",
      "|         789|     Local|             50|         T129|         G7|\n",
      "+------------+----------+---------------+-------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_train_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "616514ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f79c4eca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dropduplicates = train_df.dropDuplicates([\"train_number\",\"ticket_number\"])\n",
    "df_dropduplicates.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36310d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct_trains_df = train_df.select(\"train_name\").distinct()\n",
    "distinct_trains_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bafdb2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df=spark.read \\\n",
    ".format('json') \\\n",
    ".option(\"header\",\"true\") \\\n",
    ".option(\"inferSchema\", \"true\") \\\n",
    ".option(\"mode\",\"permissive\") \\\n",
    ".load(\"/public/trendytech/datasets/sales_data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c8024bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------+--------+-------+--------+\n",
      "|_corrupt_record|   product|quantity|revenue|store_id|\n",
      "+---------------+----------+--------+-------+--------+\n",
      "|           null|     Apple|      10|  100.0|       1|\n",
      "|           null|    Banana|      15|   75.0|       2|\n",
      "|           null|    Orange|      12|   90.0|       3|\n",
      "|           null|     Mango|       8|  120.0|       4|\n",
      "|           null|     Grape|      20|  150.0|       5|\n",
      "|           null|Watermelon|       5|   50.0|       6|\n",
      "|           null|Strawberry|      18|  108.0|       7|\n",
      "|           null| Pineapple|      14|  140.0|       8|\n",
      "|           null|    Cherry|       7|  105.0|       9|\n",
      "|           null|      Pear|       9|   81.0|      10|\n",
      "|           null| Blueberry|      11|   88.0|      11|\n",
      "|           null|      Kiwi|      16|  128.0|      12|\n",
      "|           null|     Peach|      13|   91.0|      13|\n",
      "|           null|      Plum|       6|   54.0|      14|\n",
      "|           null|     Lemon|      10|   70.0|      15|\n",
      "|           null| Raspberry|      17|  136.0|      16|\n",
      "|           null|   Coconut|       4|   80.0|      17|\n",
      "|           null|   Avocado|      11|   99.0|      18|\n",
      "|           null|Blackberry|       8|   64.0|      19|\n",
      "|           null|         G| Invalid|    NaN|      20|\n",
      "+---------------+----------+--------+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72929972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records on Permissive Mode: 22\n"
     ]
    }
   ],
   "source": [
    "no_of_records = sales_df.count()\n",
    "print(\"Number of records on Permissive Mode:\",no_of_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ac992797",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df=spark.read \\\n",
    ".format('json') \\\n",
    ".option(\"header\",\"true\") \\\n",
    ".option(\"inferSchema\", \"true\") \\\n",
    ".option(\"mode\",\"dropmalformed\") \\\n",
    ".load(\"/public/trendytech/datasets/sales_data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f048404e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records on dropmalformed Mode: 21\n"
     ]
    }
   ],
   "source": [
    "no_of_records = sales_df.count()\n",
    "print(\"Number of records on dropmalformed Mode:\",no_of_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d92eea42",
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_schema = \"pateint_id int, admission_date date, discharge_date date, diagnosis string, doctor_id int, total_cost float\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "846a04cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_df=spark.read \\\n",
    ".format(\"csv\") \\\n",
    ".option(\"header\",\"true\") \\\n",
    ".option(\"dateFormat\",\"MM-dd-yyyy\") \\\n",
    ".schema(hospital_schema) \\\n",
    ".load(\"/public/trendytech/datasets/hospital.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "27f15f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+--------------+-------------+---------+----------+\n",
      "|pateint_id|admission_date|discharge_date|    diagnosis|doctor_id|total_cost|\n",
      "+----------+--------------+--------------+-------------+---------+----------+\n",
      "|         1|    2022-01-01|    2022-01-10|    Pneumonia|      101|    5000.0|\n",
      "|         2|    2022-02-05|    2022-02-09| Appendicitis|      102|    7000.0|\n",
      "|         3|    2022-03-12|    2022-03-18|Fractured Arm|      103|    3500.0|\n",
      "|         4|    2022-04-02|    2022-04-08| Heart Attack|      104|   15000.0|\n",
      "|         5|    2022-05-05|    2022-05-07|    Influenza|      105|    2500.0|\n",
      "|         6|    2022-06-10|    2022-06-15| Appendicitis|      106|    8000.0|\n",
      "|         7|    2022-07-20|    2022-07-25|    Pneumonia|      107|    5500.0|\n",
      "|         8|    2022-08-25|    2022-09-01| Heart Attack|      108|   20000.0|\n",
      "|         9|    2022-09-15|    2022-09-22|Fractured Leg|      109|    6000.0|\n",
      "|        10|    2022-10-05|    2022-10-10| Appendicitis|      110|    7500.0|\n",
      "|        11|    2022-11-02|    2022-11-05|    Influenza|      111|    2800.0|\n",
      "|        12|    2022-12-10|    2022-12-18|    Pneumonia|      112|    6000.0|\n",
      "|        13|    2023-01-02|    2023-01-09| Heart Attack|      113|   18000.0|\n",
      "|        14|    2023-02-14|    2023-02-18| Appendicitis|      114|    7200.0|\n",
      "|        15|    2023-03-20|    2023-03-28|Fractured Arm|      115|    3800.0|\n",
      "|        16|    2023-04-05|    2023-04-11|    Influenza|      116|    2700.0|\n",
      "|        17|    2023-05-08|    2023-05-11| Heart Attack|      117|   16000.0|\n",
      "|        18|    2023-06-15|    2023-06-20|    Pneumonia|      118|    4800.0|\n",
      "|        19|    2023-07-22|    2023-07-27|Fractured Leg|      119|    6500.0|\n",
      "|        20|    2023-08-10|    2023-08-16| Appendicitis|      120|    7800.0|\n",
      "+----------+--------------+--------------+-------------+---------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hospital_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "61897b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- pateint_id: integer (nullable = true)\n",
      " |-- admission_date: date (nullable = true)\n",
      " |-- discharge_date: date (nullable = true)\n",
      " |-- diagnosis: string (nullable = true)\n",
      " |-- doctor_id: integer (nullable = true)\n",
      " |-- total_cost: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hospital_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ee0e747c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+--------------+-------------+----------+\n",
      "|pateint_id|admission_date|discharge_date|    diagnosis|total_cost|\n",
      "+----------+--------------+--------------+-------------+----------+\n",
      "|         1|    2022-01-01|    2022-01-10|    Pneumonia|    5000.0|\n",
      "|         2|    2022-02-05|    2022-02-09| Appendicitis|    7000.0|\n",
      "|         3|    2022-03-12|    2022-03-18|Fractured Arm|    3500.0|\n",
      "|         4|    2022-04-02|    2022-04-08| Heart Attack|   15000.0|\n",
      "|         5|    2022-05-05|    2022-05-07|    Influenza|    2500.0|\n",
      "|         6|    2022-06-10|    2022-06-15| Appendicitis|    8000.0|\n",
      "|         7|    2022-07-20|    2022-07-25|    Pneumonia|    5500.0|\n",
      "|         8|    2022-08-25|    2022-09-01| Heart Attack|   20000.0|\n",
      "|         9|    2022-09-15|    2022-09-22|Fractured Leg|    6000.0|\n",
      "|        10|    2022-10-05|    2022-10-10| Appendicitis|    7500.0|\n",
      "|        11|    2022-11-02|    2022-11-05|    Influenza|    2800.0|\n",
      "|        12|    2022-12-10|    2022-12-18|    Pneumonia|    6000.0|\n",
      "|        13|    2023-01-02|    2023-01-09| Heart Attack|   18000.0|\n",
      "|        14|    2023-02-14|    2023-02-18| Appendicitis|    7200.0|\n",
      "|        15|    2023-03-20|    2023-03-28|Fractured Arm|    3800.0|\n",
      "|        16|    2023-04-05|    2023-04-11|    Influenza|    2700.0|\n",
      "|        17|    2023-05-08|    2023-05-11| Heart Attack|   16000.0|\n",
      "|        18|    2023-06-15|    2023-06-20|    Pneumonia|    4800.0|\n",
      "|        19|    2023-07-22|    2023-07-27|Fractured Leg|    6500.0|\n",
      "|        20|    2023-08-10|    2023-08-16| Appendicitis|    7800.0|\n",
      "+----------+--------------+--------------+-------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dropped_df = hospital_df.drop(\"doctor_id\")\n",
    "dropped_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5118b662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+--------------+-------------+---------+-------------+\n",
      "|pateint_id|admission_date|discharge_date|    diagnosis|doctor_id|hospital_bill|\n",
      "+----------+--------------+--------------+-------------+---------+-------------+\n",
      "|         1|    2022-01-01|    2022-01-10|    Pneumonia|      101|       5000.0|\n",
      "|         2|    2022-02-05|    2022-02-09| Appendicitis|      102|       7000.0|\n",
      "|         3|    2022-03-12|    2022-03-18|Fractured Arm|      103|       3500.0|\n",
      "|         4|    2022-04-02|    2022-04-08| Heart Attack|      104|      15000.0|\n",
      "|         5|    2022-05-05|    2022-05-07|    Influenza|      105|       2500.0|\n",
      "|         6|    2022-06-10|    2022-06-15| Appendicitis|      106|       8000.0|\n",
      "|         7|    2022-07-20|    2022-07-25|    Pneumonia|      107|       5500.0|\n",
      "|         8|    2022-08-25|    2022-09-01| Heart Attack|      108|      20000.0|\n",
      "|         9|    2022-09-15|    2022-09-22|Fractured Leg|      109|       6000.0|\n",
      "|        10|    2022-10-05|    2022-10-10| Appendicitis|      110|       7500.0|\n",
      "|        11|    2022-11-02|    2022-11-05|    Influenza|      111|       2800.0|\n",
      "|        12|    2022-12-10|    2022-12-18|    Pneumonia|      112|       6000.0|\n",
      "|        13|    2023-01-02|    2023-01-09| Heart Attack|      113|      18000.0|\n",
      "|        14|    2023-02-14|    2023-02-18| Appendicitis|      114|       7200.0|\n",
      "|        15|    2023-03-20|    2023-03-28|Fractured Arm|      115|       3800.0|\n",
      "|        16|    2023-04-05|    2023-04-11|    Influenza|      116|       2700.0|\n",
      "|        17|    2023-05-08|    2023-05-11| Heart Attack|      117|      16000.0|\n",
      "|        18|    2023-06-15|    2023-06-20|    Pneumonia|      118|       4800.0|\n",
      "|        19|    2023-07-22|    2023-07-27|Fractured Leg|      119|       6500.0|\n",
      "|        20|    2023-08-10|    2023-08-16| Appendicitis|      120|       7800.0|\n",
      "+----------+--------------+--------------+-------------+---------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "renamed_df = hospital_df.withColumnRenamed(\"total_cost\",\"hospital_bill\")\n",
    "renamed_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8ff553f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "600453a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+--------------+-------------+---------+----------+--------------+\n",
      "|pateint_id|admission_date|discharge_date|    diagnosis|doctor_id|total_cost|DurationofStay|\n",
      "+----------+--------------+--------------+-------------+---------+----------+--------------+\n",
      "|         1|    2022-01-01|    2022-01-10|    Pneumonia|      101|    5000.0|             9|\n",
      "|         2|    2022-02-05|    2022-02-09| Appendicitis|      102|    7000.0|             4|\n",
      "|         3|    2022-03-12|    2022-03-18|Fractured Arm|      103|    3500.0|             6|\n",
      "|         4|    2022-04-02|    2022-04-08| Heart Attack|      104|   15000.0|             6|\n",
      "|         5|    2022-05-05|    2022-05-07|    Influenza|      105|    2500.0|             2|\n",
      "|         6|    2022-06-10|    2022-06-15| Appendicitis|      106|    8000.0|             5|\n",
      "|         7|    2022-07-20|    2022-07-25|    Pneumonia|      107|    5500.0|             5|\n",
      "|         8|    2022-08-25|    2022-09-01| Heart Attack|      108|   20000.0|             7|\n",
      "|         9|    2022-09-15|    2022-09-22|Fractured Leg|      109|    6000.0|             7|\n",
      "|        10|    2022-10-05|    2022-10-10| Appendicitis|      110|    7500.0|             5|\n",
      "|        11|    2022-11-02|    2022-11-05|    Influenza|      111|    2800.0|             3|\n",
      "|        12|    2022-12-10|    2022-12-18|    Pneumonia|      112|    6000.0|             8|\n",
      "|        13|    2023-01-02|    2023-01-09| Heart Attack|      113|   18000.0|             7|\n",
      "|        14|    2023-02-14|    2023-02-18| Appendicitis|      114|    7200.0|             4|\n",
      "|        15|    2023-03-20|    2023-03-28|Fractured Arm|      115|    3800.0|             8|\n",
      "|        16|    2023-04-05|    2023-04-11|    Influenza|      116|    2700.0|             6|\n",
      "|        17|    2023-05-08|    2023-05-11| Heart Attack|      117|   16000.0|             3|\n",
      "|        18|    2023-06-15|    2023-06-20|    Pneumonia|      118|    4800.0|             5|\n",
      "|        19|    2023-07-22|    2023-07-27|Fractured Leg|      119|    6500.0|             5|\n",
      "|        20|    2023-08-10|    2023-08-16| Appendicitis|      120|    7800.0|             6|\n",
      "+----------+--------------+--------------+-------------+---------+----------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_column_df = hospital_df.withColumn(\"DurationofStay\", expr(\"datediff(discharge_date,admission_date)\"))\n",
    "new_column_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fd119ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+--------------+-------------+---------+-------------+-------------------+\n",
      "|pateint_id|admission_date|discharge_date|    diagnosis|doctor_id|hospital_bill|adjusted_total_cost|\n",
      "+----------+--------------+--------------+-------------+---------+-------------+-------------------+\n",
      "|         1|    2022-01-01|    2022-01-10|    Pneumonia|      101|       5000.0|             5000.0|\n",
      "|         2|    2022-02-05|    2022-02-09| Appendicitis|      102|       7000.0|             8400.0|\n",
      "|         3|    2022-03-12|    2022-03-18|Fractured Arm|      103|       3500.0|             3500.0|\n",
      "|         4|    2022-04-02|    2022-04-08| Heart Attack|      104|      15000.0|            15000.0|\n",
      "|         5|    2022-05-05|    2022-05-07|    Influenza|      105|       2500.0|             2500.0|\n",
      "|         6|    2022-06-10|    2022-06-15| Appendicitis|      106|       8000.0|             9600.0|\n",
      "|         7|    2022-07-20|    2022-07-25|    Pneumonia|      107|       5500.0|             5500.0|\n",
      "|         8|    2022-08-25|    2022-09-01| Heart Attack|      108|      20000.0|            20000.0|\n",
      "|         9|    2022-09-15|    2022-09-22|Fractured Leg|      109|       6000.0|             6000.0|\n",
      "|        10|    2022-10-05|    2022-10-10| Appendicitis|      110|       7500.0|             9000.0|\n",
      "|        11|    2022-11-02|    2022-11-05|    Influenza|      111|       2800.0|             2800.0|\n",
      "|        12|    2022-12-10|    2022-12-18|    Pneumonia|      112|       6000.0|             6000.0|\n",
      "|        13|    2023-01-02|    2023-01-09| Heart Attack|      113|      18000.0|            18000.0|\n",
      "|        14|    2023-02-14|    2023-02-18| Appendicitis|      114|       7200.0|             8640.0|\n",
      "|        15|    2023-03-20|    2023-03-28|Fractured Arm|      115|       3800.0|             3800.0|\n",
      "|        16|    2023-04-05|    2023-04-11|    Influenza|      116|       2700.0|             2700.0|\n",
      "|        17|    2023-05-08|    2023-05-11| Heart Attack|      117|      16000.0|            16000.0|\n",
      "|        18|    2023-06-15|    2023-06-20|    Pneumonia|      118|       4800.0|             4800.0|\n",
      "|        19|    2023-07-22|    2023-07-27|Fractured Leg|      119|       6500.0|             6500.0|\n",
      "|        20|    2023-08-10|    2023-08-16| Appendicitis|      120|       7800.0|             9360.0|\n",
      "+----------+--------------+--------------+-------------+---------+-------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "adjusted_cost_df = renamed_df.withColumn(\"adjusted_total_cost\",expr(\"CASE WHEN diagnosis LIKE 'HeartAttack' THEN hospital_bill*1.5 WHEN diagnosis LIKE 'Appendicitis' THEN hospital_bill*1.2 ELSE hospital_bill END\"))\n",
    "adjusted_cost_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "810852cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+-------------+-------------------+\n",
      "|pateint_id|    diagnosis|hospital_bill|adjusted_total_cost|\n",
      "+----------+-------------+-------------+-------------------+\n",
      "|         1|    Pneumonia|       5000.0|             5000.0|\n",
      "|         2| Appendicitis|       7000.0|             8400.0|\n",
      "|         3|Fractured Arm|       3500.0|             3500.0|\n",
      "|         4| Heart Attack|      15000.0|            15000.0|\n",
      "|         5|    Influenza|       2500.0|             2500.0|\n",
      "|         6| Appendicitis|       8000.0|             9600.0|\n",
      "|         7|    Pneumonia|       5500.0|             5500.0|\n",
      "|         8| Heart Attack|      20000.0|            20000.0|\n",
      "|         9|Fractured Leg|       6000.0|             6000.0|\n",
      "|        10| Appendicitis|       7500.0|             9000.0|\n",
      "|        11|    Influenza|       2800.0|             2800.0|\n",
      "|        12|    Pneumonia|       6000.0|             6000.0|\n",
      "|        13| Heart Attack|      18000.0|            18000.0|\n",
      "|        14| Appendicitis|       7200.0|             8640.0|\n",
      "|        15|Fractured Arm|       3800.0|             3800.0|\n",
      "|        16|    Influenza|       2700.0|             2700.0|\n",
      "|        17| Heart Attack|      16000.0|            16000.0|\n",
      "|        18|    Pneumonia|       4800.0|             4800.0|\n",
      "|        19|Fractured Leg|       6500.0|             6500.0|\n",
      "|        20| Appendicitis|       7800.0|             9360.0|\n",
      "+----------+-------------+-------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "adjusted_cost_df.select(\"pateint_id\",\"diagnosis\",\"hospital_bill\",\"adjusted_total_cost\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "559b11aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53ac91b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 3",
   "language": "python",
   "name": "pyspark3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
