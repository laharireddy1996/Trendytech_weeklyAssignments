{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fefc5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import getpass\n",
    "username = getpass.getuser()\n",
    "spark = SparkSession. \\\n",
    "builder. \\\n",
    "config('spark.ui.port','0'). \\\n",
    "config('spark.shuffle.useOldFetchProtocol', 'true'). \\\n",
    "config(\"spark.sql.warehouse.dir\",f\"/user/itv016269/warehouse\"). \\\n",
    "enableHiveSupport(). \\\n",
    "master('yarn'). \\\n",
    "getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4cff29ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_trans_schema = \"customer_id int, purchase_date date, product_id int, amount double\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dae77f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_transf_df=spark.read \\\n",
    ".format('csv') \\\n",
    ".option(\"dateFormat\",\"dd/mm/yyyy\") \\\n",
    ".schema(cust_trans_schema) \\\n",
    ".load(\"/public/trendytech/datasets/cust_transf.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8d666a",
   "metadata": {},
   "source": [
    "A.1 Your marketing team wants to identify the top-selling products based on\n",
    "revenue for a given time period. The query is expected to be executed\n",
    "frequently, and the results need to be returned quickly. Design a caching\n",
    "strategy that efficiently retrieves the top-selling products by revenue.\n",
    "Additionally, demonstrate the impact of caching by comparing the retrieval\n",
    "time for Top 10 best-selling products from start_date = \"2023-05-01\" to\n",
    "end_date = \"2023-06-08\" before and after implementing the caching strategy.\n",
    "[Note : Strategize your caching in such a way that the right Dataframes are\n",
    "cached at the right time for maximal performance gains]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3b80d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87498290"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust_transf_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c032c6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date=\"2023-05-01\"\n",
    "end_date=\"2023-06-08\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b543757",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = cust_transf_df.filter((cust_transf_df.purchase_date >= start_date) & (cust_transf_df.purchase_date <= end_date)).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60e72ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import round\n",
    "\n",
    "revenue_df = filtered_df.groupBy('product_id').sum('amount').withColumnRenamed(\"sum(amount)\", \"revenue\")\n",
    "revenue_new_df = revenue_df.select(\"*\",round(\"revenue\",2).alias(\"new_revenue\")).drop(\"revenue\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4b48e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+\n",
      "|product_id|   new_revenue|\n",
      "+----------+--------------+\n",
      "|      1005| 2.782856412E8|\n",
      "|      1008|       5222.91|\n",
      "|      1010|       7312.91|\n",
      "|      1002|4.2938362439E8|\n",
      "|      1015|      12537.91|\n",
      "|      1001|5.5668264119E8|\n",
      "|      1006|       3132.91|\n",
      "|      1007|       4177.91|\n",
      "|      1003|5.7255922439E8|\n",
      "|      1014|      11492.91|\n",
      "|      1004| 2.862080244E8|\n",
      "|      1011|       8357.91|\n",
      "|      1012|       9402.91|\n",
      "|      1013|      10447.91|\n",
      "|      1009|       6267.91|\n",
      "+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "revenue_new_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5485bf8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+\n",
      "|product_id|             revenue|\n",
      "+----------+--------------------+\n",
      "|      1003| 5.725592243903786E8|\n",
      "|      1001|  5.56682641192824E8|\n",
      "|      1002|4.2938362439486474E8|\n",
      "|      1004|2.8620802440276194E8|\n",
      "|      1005| 2.782856412021384E8|\n",
      "|      1015|  12537.909999999963|\n",
      "|      1014|  11492.909999999963|\n",
      "|      1013|  10447.909999999963|\n",
      "|      1012|   9402.909999999965|\n",
      "|      1011|   8357.909999999967|\n",
      "+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_products = revenue_df.sort(\"revenue\",ascending=False).limit(10)\n",
    "top_products.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cfcb07",
   "metadata": {},
   "source": [
    "A.2 Find the top 10 customers with maximum transaction amount for the same\n",
    "date range of start_date = \"2023-05-01\" to end_date = \"2023-06-08\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fbf28294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+----------+------+\n",
      "|customer_id|purchase_date|product_id|amount|\n",
      "+-----------+-------------+----------+------+\n",
      "|       1015|   2023-05-31|      1015| 59.99|\n",
      "|       1015|   2023-05-31|      1015| 59.99|\n",
      "|       1015|   2023-05-31|      1015| 59.99|\n",
      "|       1015|   2023-05-31|      1015| 59.99|\n",
      "|       1015|   2023-05-31|      1015| 59.99|\n",
      "|       1015|   2023-05-31|      1015| 59.99|\n",
      "|       1015|   2023-05-31|      1015| 59.99|\n",
      "|       1015|   2023-05-31|      1015| 59.99|\n",
      "|       1015|   2023-05-31|      1015| 59.99|\n",
      "|       1015|   2023-05-31|      1015| 59.99|\n",
      "+-----------+-------------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_customers = filtered_df.sort(\"amount\",ascending=False).limit(10)\n",
    "top_customers.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84e319fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>database</th><th>tableName</th><th>isTemporary</th></tr>\n",
       "<tr><td>itv016269_databases</td><td>cust_transf_ext</td><td>false</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------------------+---------------+-----------+\n",
       "|           database|      tableName|isTemporary|\n",
       "+-------------------+---------------+-----------+\n",
       "|itv016269_databases|cust_transf_ext|      false|\n",
       "+-------------------+---------------+-----------+"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"use itv016269_databases\")\n",
    "spark.sql(\"show tables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0f7d0039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th></th></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"drop table itv016269_databases.cust_transf_ext \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f1d1539d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th></th></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"create table itv016269_databases.cust_transf_ext ( customer_id int, purchase_date date, product_id int, amount double) using csv location '/public/trendytech/datasets/cust_transf.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a878970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th></th></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"cache table itv016269_databases.cust_transf_ext\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7b75df8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th></th></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"uncache table itv016269_databases.cust_transf_ext\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "baf88f92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>customer_id</th><th>purchase_date</th><th>product_id</th><th>amount</th></tr>\n",
       "<tr><td>1005</td><td>2023-06-08</td><td>1002</td><td>29.99</td></tr>\n",
       "<tr><td>1008</td><td>2023-06-08</td><td>1004</td><td>19.99</td></tr>\n",
       "<tr><td>1009</td><td>2023-06-09</td><td>1005</td><td>24.99</td></tr>\n",
       "<tr><td>1010</td><td>2023-06-10</td><td>1001</td><td>49.99</td></tr>\n",
       "<tr><td>1006</td><td>2023-06-11</td><td>1003</td><td>39.99</td></tr>\n",
       "<tr><td>1007</td><td>2023-06-12</td><td>1004</td><td>19.99</td></tr>\n",
       "<tr><td>1008</td><td>2023-06-13</td><td>1005</td><td>24.99</td></tr>\n",
       "<tr><td>1009</td><td>2023-06-14</td><td>1001</td><td>49.99</td></tr>\n",
       "<tr><td>1010</td><td>2023-06-15</td><td>1002</td><td>29.99</td></tr>\n",
       "<tr><td>1013</td><td>2023-06-08</td><td>1004</td><td>19.99</td></tr>\n",
       "<tr><td>1014</td><td>2023-06-09</td><td>1005</td><td>24.99</td></tr>\n",
       "<tr><td>1015</td><td>2023-06-10</td><td>1001</td><td>49.99</td></tr>\n",
       "<tr><td>1011</td><td>2023-06-11</td><td>1003</td><td>39.99</td></tr>\n",
       "<tr><td>1012</td><td>2023-06-12</td><td>1004</td><td>19.99</td></tr>\n",
       "<tr><td>1013</td><td>2023-06-13</td><td>1005</td><td>24.99</td></tr>\n",
       "<tr><td>1014</td><td>2023-06-14</td><td>1001</td><td>49.99</td></tr>\n",
       "<tr><td>1015</td><td>2023-06-15</td><td>1002</td><td>29.99</td></tr>\n",
       "<tr><td>1005</td><td>2023-06-08</td><td>1002</td><td>29.99</td></tr>\n",
       "<tr><td>1008</td><td>2023-06-08</td><td>1004</td><td>19.99</td></tr>\n",
       "<tr><td>1009</td><td>2023-06-09</td><td>1005</td><td>24.99</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+-----------+-------------+----------+------+\n",
       "|customer_id|purchase_date|product_id|amount|\n",
       "+-----------+-------------+----------+------+\n",
       "|       1005|   2023-06-08|      1002| 29.99|\n",
       "|       1008|   2023-06-08|      1004| 19.99|\n",
       "|       1009|   2023-06-09|      1005| 24.99|\n",
       "|       1010|   2023-06-10|      1001| 49.99|\n",
       "|       1006|   2023-06-11|      1003| 39.99|\n",
       "|       1007|   2023-06-12|      1004| 19.99|\n",
       "|       1008|   2023-06-13|      1005| 24.99|\n",
       "|       1009|   2023-06-14|      1001| 49.99|\n",
       "|       1010|   2023-06-15|      1002| 29.99|\n",
       "|       1013|   2023-06-08|      1004| 19.99|\n",
       "|       1014|   2023-06-09|      1005| 24.99|\n",
       "|       1015|   2023-06-10|      1001| 49.99|\n",
       "|       1011|   2023-06-11|      1003| 39.99|\n",
       "|       1012|   2023-06-12|      1004| 19.99|\n",
       "|       1013|   2023-06-13|      1005| 24.99|\n",
       "|       1014|   2023-06-14|      1001| 49.99|\n",
       "|       1015|   2023-06-15|      1002| 29.99|\n",
       "|       1005|   2023-06-08|      1002| 29.99|\n",
       "|       1008|   2023-06-08|      1004| 19.99|\n",
       "|       1009|   2023-06-09|      1005| 24.99|\n",
       "+-----------+-------------+----------+------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select * from cust_transf_ext where purchase_date >= '2023-05-01' and purchase_date >= '2023-06-08'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e16ce49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+\n",
      "|product_id|             revenue|\n",
      "+----------+--------------------+\n",
      "|      1001|3.1810436640042645E8|\n",
      "|      1005|1.5902036640107167E8|\n",
      "|      1002| 1.431278748007746E8|\n",
      "|      1003|1.2723538320049205E8|\n",
      "|      1004|1.2720356640098402E8|\n",
      "+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select product_id, sum(amount) as revenue from cust_transf_ext where purchase_date >= '2023-05-01' and purchase_date >= '2023-06-08' group by product_id order by revenue desc limit 10 \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6c72f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+\n",
      "|customer_id|max_transaction|\n",
      "+-----------+---------------+\n",
      "|       1015|          49.99|\n",
      "|       1006|          39.99|\n",
      "|       1007|          19.99|\n",
      "|       1014|          49.99|\n",
      "|       1009|          49.99|\n",
      "|       1010|          49.99|\n",
      "|       1008|          24.99|\n",
      "|       1005|          29.99|\n",
      "|       1013|          24.99|\n",
      "|       1011|          39.99|\n",
      "+-----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select customer_id, max(amount) as max_transaction from cust_transf_ext where purchase_date >= '2023-05-01' and purchase_date >= '2023-06-08' group by customer_id  limit 10 \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85840c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+----------+------+\n",
      "|customer_id|purchase_date|product_id|amount|\n",
      "+-----------+-------------+----------+------+\n",
      "|       1001|   2023-05-15|      1001| 49.99|\n",
      "|       1002|   2023-05-16|      1002| 29.99|\n",
      "|       1003|   2023-05-17|      1003| 39.99|\n",
      "|       1004|   2023-05-18|      1004| 19.99|\n",
      "|       1005|   2023-05-19|      1005| 24.99|\n",
      "|       1001|   2023-05-20|      1002| 29.99|\n",
      "|       1002|   2023-05-21|      1003| 39.99|\n",
      "|       1003|   2023-05-22|      1004| 19.99|\n",
      "|       1004|   2023-05-23|      1005| 24.99|\n",
      "|       1005|   2023-05-24|      1001| 49.99|\n",
      "|       1001|   2023-05-25|      1003| 39.99|\n",
      "|       1002|   2023-05-26|      1004| 19.99|\n",
      "|       1003|   2023-05-27|      1005| 24.99|\n",
      "|       1004|   2023-05-28|      1001| 49.99|\n",
      "|       1005|   2023-05-29|      1002| 29.99|\n",
      "|       1001|   2023-05-30|      1003| 39.99|\n",
      "|       1002|   2023-05-31|      1004| 19.99|\n",
      "|       1003|   2023-06-01|      1005| 24.99|\n",
      "|       1004|   2023-06-02|      1001| 49.99|\n",
      "|       1005|   2023-06-03|      1002| 29.99|\n",
      "+-----------+-------------+----------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cust_transf_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8d53ee",
   "metadata": {},
   "source": [
    "A.4 Find the top 10 regular customers based on the number of distinct months\n",
    "in which they made purchases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "692b8078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+----------+------+-------------+--------------+\n",
      "|customer_id|purchase_date|product_id|amount|purchase_year|purchase_month|\n",
      "+-----------+-------------+----------+------+-------------+--------------+\n",
      "|       1001|   2023-05-15|      1001| 49.99|         2023|             5|\n",
      "|       1002|   2023-05-16|      1002| 29.99|         2023|             5|\n",
      "|       1003|   2023-05-17|      1003| 39.99|         2023|             5|\n",
      "|       1004|   2023-05-18|      1004| 19.99|         2023|             5|\n",
      "|       1005|   2023-05-19|      1005| 24.99|         2023|             5|\n",
      "|       1001|   2023-05-20|      1002| 29.99|         2023|             5|\n",
      "|       1002|   2023-05-21|      1003| 39.99|         2023|             5|\n",
      "|       1003|   2023-05-22|      1004| 19.99|         2023|             5|\n",
      "|       1004|   2023-05-23|      1005| 24.99|         2023|             5|\n",
      "|       1005|   2023-05-24|      1001| 49.99|         2023|             5|\n",
      "|       1001|   2023-05-25|      1003| 39.99|         2023|             5|\n",
      "|       1002|   2023-05-26|      1004| 19.99|         2023|             5|\n",
      "|       1003|   2023-05-27|      1005| 24.99|         2023|             5|\n",
      "|       1004|   2023-05-28|      1001| 49.99|         2023|             5|\n",
      "|       1005|   2023-05-29|      1002| 29.99|         2023|             5|\n",
      "|       1001|   2023-05-30|      1003| 39.99|         2023|             5|\n",
      "|       1002|   2023-05-31|      1004| 19.99|         2023|             5|\n",
      "|       1003|   2023-06-01|      1005| 24.99|         2023|             6|\n",
      "|       1004|   2023-06-02|      1001| 49.99|         2023|             6|\n",
      "|       1005|   2023-06-03|      1002| 29.99|         2023|             6|\n",
      "+-----------+-------------+----------+------+-------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import year, month\n",
    "\n",
    "new_cust_df = cust_transf_df.withColumn(\"purchase_year\",year(\"purchase_date\")).withColumn(\"purchase_month\",month(\"purchase_date\"))\n",
    "new_cust_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d64da657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+--------------+---------------+\n",
      "|customer_id|purchase_year|purchase_month|distinct_months|\n",
      "+-----------+-------------+--------------+---------------+\n",
      "|       1015|         2023|             6|              1|\n",
      "|       1010|         2023|             5|              1|\n",
      "|       1015|         2023|             5|              1|\n",
      "|       1008|         2023|             6|              1|\n",
      "|       1004|         2023|             5|              1|\n",
      "|       1007|         2023|             6|              1|\n",
      "|       1009|         2023|             5|              1|\n",
      "|       1002|         2023|             6|              1|\n",
      "|       1011|         2023|             5|              1|\n",
      "|       1014|         2023|             5|              1|\n",
      "|       1003|         2023|             6|              1|\n",
      "|       1006|         2023|             6|              1|\n",
      "|       1001|         2023|             6|              1|\n",
      "|       1010|         2023|             6|              1|\n",
      "|       1012|         2023|             6|              1|\n",
      "|       1014|         2023|             6|              1|\n",
      "|       1013|         2023|             5|              1|\n",
      "|       1002|         2023|             5|              1|\n",
      "|       1001|         2023|             5|              1|\n",
      "|       1003|         2023|             5|              1|\n",
      "+-----------+-------------+--------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "\n",
    "distinct_months_df = new_cust_df.groupBy(\"customer_id\",\"purchase_year\",\"purchase_month\").agg(countDistinct(\"purchase_month\").alias(\"distinct_months\"))\n",
    "distinct_months_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16826b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|customer_id|count|\n",
      "+-----------+-----+\n",
      "|       1005|    2|\n",
      "|       1007|    2|\n",
      "|       1004|    2|\n",
      "|       1009|    2|\n",
      "|       1003|    2|\n",
      "|       1001|    2|\n",
      "|       1011|    2|\n",
      "|       1008|    2|\n",
      "|       1002|    2|\n",
      "|       1006|    2|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regular_customers = distinct_months_df.filter(\"distinct_months = 1\").groupBy(\"customer_id\").count().orderBy(\"count\",ascending = False).limit(10)\n",
    "regular_customers.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b46fc89",
   "metadata": {},
   "source": [
    "Without Caching the query took 1.5 mins to execute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df47fd29",
   "metadata": {},
   "source": [
    "Demonstrate the changes in the performance of the query A.4 for the\n",
    "following persist storage levels.\n",
    "- MEMORY_ONLY\n",
    "- MEMORY_ONLY_SER\n",
    "- MEMORY_AND_DISK\n",
    "- MEMORY_AND_DISK_SER\n",
    "- DISK_ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7640e10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import countDistinct, year, month\n",
    "\n",
    "new_cust_df = cust_transf_df.withColumn(\"purchase_year\",year(\"purchase_date\")).withColumn(\"purchase_month\",month(\"purchase_date\"))\n",
    "\n",
    "distinct_months_df = new_cust_df.groupBy(\"customer_id\",\"purchase_year\",\"purchase_month\"). \\\n",
    "                    agg(countDistinct(\"purchase_month\").alias(\"distinct_months\")).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c3b4bbb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|customer_id|count|\n",
      "+-----------+-----+\n",
      "|       1006|    2|\n",
      "|       1013|    2|\n",
      "|       1003|    2|\n",
      "|       1015|    2|\n",
      "|       1001|    2|\n",
      "|       1004|    2|\n",
      "|       1008|    2|\n",
      "|       1014|    2|\n",
      "|       1007|    2|\n",
      "|       1009|    2|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regular_customers = distinct_months_df.filter(\"distinct_months = 1\").groupBy(\"customer_id\").count(). \\\n",
    "                    orderBy(\"count\",ascending = False).limit(10)\n",
    "\n",
    "regular_customers.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b34201",
   "metadata": {},
   "source": [
    "After Caching the query took 0.9 secs to execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dbf595f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import countDistinct, year, month\n",
    "from pyspark.storagelevel import StorageLevel\n",
    "\n",
    "new_cust_df = cust_transf_df.withColumn(\"purchase_year\",year(\"purchase_date\")).withColumn(\"purchase_month\",month(\"purchase_date\"))\n",
    "\n",
    "distinct_months_df = new_cust_df.groupBy(\"customer_id\",\"purchase_year\",\"purchase_month\"). \\\n",
    "                    agg(countDistinct(\"purchase_month\").alias(\"distinct_months\")).persist(StorageLevel.MEMORY_ONLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "873181eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|customer_id|count|\n",
      "+-----------+-----+\n",
      "|       1001|    2|\n",
      "|       1004|    2|\n",
      "|       1014|    2|\n",
      "|       1013|    2|\n",
      "|       1010|    2|\n",
      "|       1011|    2|\n",
      "|       1007|    2|\n",
      "|       1012|    2|\n",
      "|       1002|    2|\n",
      "|       1003|    2|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regular_customers = distinct_months_df.filter(\"distinct_months = 1\").groupBy(\"customer_id\").count(). \\\n",
    "                    orderBy(\"count\",ascending = False).limit(10)\n",
    "\n",
    "regular_customers.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13b50ab",
   "metadata": {},
   "source": [
    "Persist with Memory only took 1 sec to execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6fc5a686",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import countDistinct, year, month\n",
    "from pyspark.storagelevel import StorageLevel\n",
    "\n",
    "new_cust_df = cust_transf_df.withColumn(\"purchase_year\",year(\"purchase_date\")).withColumn(\"purchase_month\",month(\"purchase_date\"))\n",
    "\n",
    "distinct_months_df = new_cust_df.groupBy(\"customer_id\",\"purchase_year\",\"purchase_month\"). \\\n",
    "                    agg(countDistinct(\"purchase_month\").alias(\"distinct_months\")).persist(StorageLevel.MEMORY_AND_DISK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ff320335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|customer_id|count|\n",
      "+-----------+-----+\n",
      "|       1010|    2|\n",
      "|       1009|    2|\n",
      "|       1002|    2|\n",
      "|       1007|    2|\n",
      "|       1012|    2|\n",
      "|       1005|    2|\n",
      "|       1011|    2|\n",
      "|       1015|    2|\n",
      "|       1006|    2|\n",
      "|       1004|    2|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regular_customers = distinct_months_df.filter(\"distinct_months = 1\").groupBy(\"customer_id\").count(). \\\n",
    "                    orderBy(\"count\",ascending = False).limit(10)\n",
    "\n",
    "regular_customers.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4e747a",
   "metadata": {},
   "source": [
    "Persist with Memory and Disk took 1 sec to execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "211fcd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import countDistinct, year, month\n",
    "from pyspark.storagelevel import StorageLevel\n",
    "\n",
    "new_cust_df = cust_transf_df.withColumn(\"purchase_year\",year(\"purchase_date\")).withColumn(\"purchase_month\",month(\"purchase_date\"))\n",
    "\n",
    "distinct_months_df = new_cust_df.groupBy(\"customer_id\",\"purchase_year\",\"purchase_month\"). \\\n",
    "                    agg(countDistinct(\"purchase_month\").alias(\"distinct_months\")).persist(StorageLevel.DISK_ONLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "19b04f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|customer_id|count|\n",
      "+-----------+-----+\n",
      "|       1014|    2|\n",
      "|       1007|    2|\n",
      "|       1011|    2|\n",
      "|       1008|    2|\n",
      "|       1006|    2|\n",
      "|       1010|    2|\n",
      "|       1012|    2|\n",
      "|       1005|    2|\n",
      "|       1002|    2|\n",
      "|       1009|    2|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regular_customers = distinct_months_df.filter(\"distinct_months = 1\").groupBy(\"customer_id\").count(). \\\n",
    "                    orderBy(\"count\",ascending = False).limit(10)\n",
    "\n",
    "regular_customers.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f523e0e",
   "metadata": {},
   "source": [
    "Persist with Disk only took 1 sec to execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f5365acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_customer_history(customer_id):\n",
    "    customer_history_df = cust_transf_df.filter(cust_transf_df.customer_id == customer_id).cache()\n",
    "    return customer_history_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3deada61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+----------+------+\n",
      "|customer_id|purchase_date|product_id|amount|\n",
      "+-----------+-------------+----------+------+\n",
      "|       1001|   2023-05-15|      1001| 49.99|\n",
      "|       1001|   2023-05-20|      1002| 29.99|\n",
      "|       1001|   2023-05-25|      1003| 39.99|\n",
      "|       1001|   2023-05-30|      1003| 39.99|\n",
      "|       1001|   2023-06-04|      1003| 39.99|\n",
      "|       1001|   2023-05-15|      1001| 49.99|\n",
      "|       1001|   2023-05-20|      1002| 29.99|\n",
      "|       1001|   2023-05-25|      1003| 39.99|\n",
      "|       1001|   2023-05-30|      1003| 39.99|\n",
      "|       1001|   2023-06-04|      1003| 39.99|\n",
      "|       1001|   2023-05-15|      1001| 49.99|\n",
      "|       1001|   2023-05-20|      1002| 29.99|\n",
      "|       1001|   2023-05-25|      1003| 39.99|\n",
      "|       1001|   2023-05-30|      1003| 39.99|\n",
      "|       1001|   2023-06-04|      1003| 39.99|\n",
      "|       1001|   2023-05-15|      1001| 49.99|\n",
      "|       1001|   2023-05-20|      1002| 29.99|\n",
      "|       1001|   2023-05-25|      1003| 39.99|\n",
      "|       1001|   2023-05-30|      1003| 39.99|\n",
      "|       1001|   2023-06-04|      1003| 39.99|\n",
      "+-----------+-------------+----------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customer_id=1001\n",
    "customer_history_df = get_customer_history(customer_id)\n",
    "customer_history_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "258707d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>customer_id</th><th>purchase_date</th><th>product_id</th><th>amount</th></tr>\n",
       "<tr><td>1001</td><td>2023-05-15</td><td>1001</td><td>49.99</td></tr>\n",
       "<tr><td>1001</td><td>2023-05-20</td><td>1002</td><td>29.99</td></tr>\n",
       "<tr><td>1001</td><td>2023-05-25</td><td>1003</td><td>39.99</td></tr>\n",
       "<tr><td>1001</td><td>2023-05-30</td><td>1003</td><td>39.99</td></tr>\n",
       "<tr><td>1001</td><td>2023-06-04</td><td>1003</td><td>39.99</td></tr>\n",
       "<tr><td>1001</td><td>2023-05-15</td><td>1001</td><td>49.99</td></tr>\n",
       "<tr><td>1001</td><td>2023-05-20</td><td>1002</td><td>29.99</td></tr>\n",
       "<tr><td>1001</td><td>2023-05-25</td><td>1003</td><td>39.99</td></tr>\n",
       "<tr><td>1001</td><td>2023-05-30</td><td>1003</td><td>39.99</td></tr>\n",
       "<tr><td>1001</td><td>2023-06-04</td><td>1003</td><td>39.99</td></tr>\n",
       "<tr><td>1001</td><td>2023-05-15</td><td>1001</td><td>49.99</td></tr>\n",
       "<tr><td>1001</td><td>2023-05-20</td><td>1002</td><td>29.99</td></tr>\n",
       "<tr><td>1001</td><td>2023-05-25</td><td>1003</td><td>39.99</td></tr>\n",
       "<tr><td>1001</td><td>2023-05-30</td><td>1003</td><td>39.99</td></tr>\n",
       "<tr><td>1001</td><td>2023-06-04</td><td>1003</td><td>39.99</td></tr>\n",
       "<tr><td>1001</td><td>2023-05-15</td><td>1001</td><td>49.99</td></tr>\n",
       "<tr><td>1001</td><td>2023-05-20</td><td>1002</td><td>29.99</td></tr>\n",
       "<tr><td>1001</td><td>2023-05-25</td><td>1003</td><td>39.99</td></tr>\n",
       "<tr><td>1001</td><td>2023-05-30</td><td>1003</td><td>39.99</td></tr>\n",
       "<tr><td>1001</td><td>2023-06-04</td><td>1003</td><td>39.99</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+-----------+-------------+----------+------+\n",
       "|customer_id|purchase_date|product_id|amount|\n",
       "+-----------+-------------+----------+------+\n",
       "|       1001|   2023-05-15|      1001| 49.99|\n",
       "|       1001|   2023-05-20|      1002| 29.99|\n",
       "|       1001|   2023-05-25|      1003| 39.99|\n",
       "|       1001|   2023-05-30|      1003| 39.99|\n",
       "|       1001|   2023-06-04|      1003| 39.99|\n",
       "|       1001|   2023-05-15|      1001| 49.99|\n",
       "|       1001|   2023-05-20|      1002| 29.99|\n",
       "|       1001|   2023-05-25|      1003| 39.99|\n",
       "|       1001|   2023-05-30|      1003| 39.99|\n",
       "|       1001|   2023-06-04|      1003| 39.99|\n",
       "|       1001|   2023-05-15|      1001| 49.99|\n",
       "|       1001|   2023-05-20|      1002| 29.99|\n",
       "|       1001|   2023-05-25|      1003| 39.99|\n",
       "|       1001|   2023-05-30|      1003| 39.99|\n",
       "|       1001|   2023-06-04|      1003| 39.99|\n",
       "|       1001|   2023-05-15|      1001| 49.99|\n",
       "|       1001|   2023-05-20|      1002| 29.99|\n",
       "|       1001|   2023-05-25|      1003| 39.99|\n",
       "|       1001|   2023-05-30|      1003| 39.99|\n",
       "|       1001|   2023-06-04|      1003| 39.99|\n",
       "+-----------+-------------+----------+------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_history_df.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5dea21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hotels_schema = \"booking_id int, guest_name string, checkin_date date, checkout_date date, room_type string, total_price float\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3773f417",
   "metadata": {},
   "outputs": [],
   "source": [
    "hotels_df = spark.read. \\\n",
    "format(\"csv\"). \\\n",
    "schema(hotels_schema). \\\n",
    "load(\"/public/trendytech/datasets/hotel_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ad77d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+------------+-------------+---------+-----------+\n",
      "|booking_id|       guest_name|checkin_date|checkout_date|room_type|total_price|\n",
      "+----------+-----------------+------------+-------------+---------+-----------+\n",
      "|         1|         John Doe|  2023-05-01|   2023-05-05| Standard|      400.0|\n",
      "|         2|       Jane Smith|  2023-05-02|   2023-05-06|   Deluxe|      600.0|\n",
      "|         3|     Mark Johnson|  2023-05-03|   2023-05-08| Standard|      450.0|\n",
      "|         4|     Sarah Wilson|  2023-05-04|   2023-05-07|Executive|      750.0|\n",
      "|         5|      Emily Brown|  2023-05-06|   2023-05-09|   Deluxe|      550.0|\n",
      "|         6|    Michael Davis|  2023-05-07|   2023-05-10| Standard|      400.0|\n",
      "|         7|Samantha Thompson|  2023-05-08|   2023-05-12|   Deluxe|      600.0|\n",
      "|         8|      William Lee|  2023-05-10|   2023-05-13| Standard|      450.0|\n",
      "|         9|    Amanda Harris|  2023-05-11|   2023-05-16|Executive|      750.0|\n",
      "|        10|  David Rodriguez|  2023-05-12|   2023-05-15|   Deluxe|      550.0|\n",
      "|        11|     Linda Wilson|  2023-05-14|   2023-05-18| Standard|      400.0|\n",
      "|        12|   Robert Johnson|  2023-05-15|   2023-05-20|   Deluxe|      600.0|\n",
      "|        13|  Sophia Anderson|  2023-05-16|   2023-05-21| Standard|      450.0|\n",
      "|        14|      James Smith|  2023-05-17|   2023-05-23|Executive|      750.0|\n",
      "|        15|     Olivia Brown|  2023-05-19|   2023-05-24|   Deluxe|      550.0|\n",
      "|        16|    Michael Davis|  2023-05-20|   2023-05-25| Standard|      400.0|\n",
      "|        17|   Emily Thompson|  2023-05-21|   2023-05-27|   Deluxe|      600.0|\n",
      "|        18|      William Lee|  2023-05-23|   2023-05-28| Standard|      450.0|\n",
      "|        19|       Ava Harris|  2023-05-24|   2023-05-30|Executive|      750.0|\n",
      "|        20| Daniel Rodriguez|  2023-05-25|   2023-05-29|   Deluxe|      550.0|\n",
      "+----------+-----------------+------------+-------------+---------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hotels_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e1f4275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th></th></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"create table itv016269_databases.hotels(booking_id int, guest_name string, checkin_date date, checkout_date date, room_type string, total_price float) using csv location '/public/trendytech/datasets/hotel_data.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5bc238a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>booking_id</th><th>guest_name</th><th>checkin_date</th><th>checkout_date</th><th>room_type</th><th>total_price</th></tr>\n",
       "<tr><td>1</td><td>John Doe</td><td>2023-05-01</td><td>2023-05-05</td><td>Standard</td><td>400.0</td></tr>\n",
       "<tr><td>2</td><td>Jane Smith</td><td>2023-05-02</td><td>2023-05-06</td><td>Deluxe</td><td>600.0</td></tr>\n",
       "<tr><td>3</td><td>Mark Johnson</td><td>2023-05-03</td><td>2023-05-08</td><td>Standard</td><td>450.0</td></tr>\n",
       "<tr><td>4</td><td>Sarah Wilson</td><td>2023-05-04</td><td>2023-05-07</td><td>Executive</td><td>750.0</td></tr>\n",
       "<tr><td>5</td><td>Emily Brown</td><td>2023-05-06</td><td>2023-05-09</td><td>Deluxe</td><td>550.0</td></tr>\n",
       "<tr><td>6</td><td>Michael Davis</td><td>2023-05-07</td><td>2023-05-10</td><td>Standard</td><td>400.0</td></tr>\n",
       "<tr><td>7</td><td>Samantha Thompson</td><td>2023-05-08</td><td>2023-05-12</td><td>Deluxe</td><td>600.0</td></tr>\n",
       "<tr><td>8</td><td>William Lee</td><td>2023-05-10</td><td>2023-05-13</td><td>Standard</td><td>450.0</td></tr>\n",
       "<tr><td>9</td><td>Amanda Harris</td><td>2023-05-11</td><td>2023-05-16</td><td>Executive</td><td>750.0</td></tr>\n",
       "<tr><td>10</td><td>David Rodriguez</td><td>2023-05-12</td><td>2023-05-15</td><td>Deluxe</td><td>550.0</td></tr>\n",
       "<tr><td>11</td><td>Linda Wilson</td><td>2023-05-14</td><td>2023-05-18</td><td>Standard</td><td>400.0</td></tr>\n",
       "<tr><td>12</td><td>Robert Johnson</td><td>2023-05-15</td><td>2023-05-20</td><td>Deluxe</td><td>600.0</td></tr>\n",
       "<tr><td>13</td><td>Sophia Anderson</td><td>2023-05-16</td><td>2023-05-21</td><td>Standard</td><td>450.0</td></tr>\n",
       "<tr><td>14</td><td>James Smith</td><td>2023-05-17</td><td>2023-05-23</td><td>Executive</td><td>750.0</td></tr>\n",
       "<tr><td>15</td><td>Olivia Brown</td><td>2023-05-19</td><td>2023-05-24</td><td>Deluxe</td><td>550.0</td></tr>\n",
       "<tr><td>16</td><td>Michael Davis</td><td>2023-05-20</td><td>2023-05-25</td><td>Standard</td><td>400.0</td></tr>\n",
       "<tr><td>17</td><td>Emily Thompson</td><td>2023-05-21</td><td>2023-05-27</td><td>Deluxe</td><td>600.0</td></tr>\n",
       "<tr><td>18</td><td>William Lee</td><td>2023-05-23</td><td>2023-05-28</td><td>Standard</td><td>450.0</td></tr>\n",
       "<tr><td>19</td><td>Ava Harris</td><td>2023-05-24</td><td>2023-05-30</td><td>Executive</td><td>750.0</td></tr>\n",
       "<tr><td>20</td><td>Daniel Rodriguez</td><td>2023-05-25</td><td>2023-05-29</td><td>Deluxe</td><td>550.0</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+----------+-----------------+------------+-------------+---------+-----------+\n",
       "|booking_id|       guest_name|checkin_date|checkout_date|room_type|total_price|\n",
       "+----------+-----------------+------------+-------------+---------+-----------+\n",
       "|         1|         John Doe|  2023-05-01|   2023-05-05| Standard|      400.0|\n",
       "|         2|       Jane Smith|  2023-05-02|   2023-05-06|   Deluxe|      600.0|\n",
       "|         3|     Mark Johnson|  2023-05-03|   2023-05-08| Standard|      450.0|\n",
       "|         4|     Sarah Wilson|  2023-05-04|   2023-05-07|Executive|      750.0|\n",
       "|         5|      Emily Brown|  2023-05-06|   2023-05-09|   Deluxe|      550.0|\n",
       "|         6|    Michael Davis|  2023-05-07|   2023-05-10| Standard|      400.0|\n",
       "|         7|Samantha Thompson|  2023-05-08|   2023-05-12|   Deluxe|      600.0|\n",
       "|         8|      William Lee|  2023-05-10|   2023-05-13| Standard|      450.0|\n",
       "|         9|    Amanda Harris|  2023-05-11|   2023-05-16|Executive|      750.0|\n",
       "|        10|  David Rodriguez|  2023-05-12|   2023-05-15|   Deluxe|      550.0|\n",
       "|        11|     Linda Wilson|  2023-05-14|   2023-05-18| Standard|      400.0|\n",
       "|        12|   Robert Johnson|  2023-05-15|   2023-05-20|   Deluxe|      600.0|\n",
       "|        13|  Sophia Anderson|  2023-05-16|   2023-05-21| Standard|      450.0|\n",
       "|        14|      James Smith|  2023-05-17|   2023-05-23|Executive|      750.0|\n",
       "|        15|     Olivia Brown|  2023-05-19|   2023-05-24|   Deluxe|      550.0|\n",
       "|        16|    Michael Davis|  2023-05-20|   2023-05-25| Standard|      400.0|\n",
       "|        17|   Emily Thompson|  2023-05-21|   2023-05-27|   Deluxe|      600.0|\n",
       "|        18|      William Lee|  2023-05-23|   2023-05-28| Standard|      450.0|\n",
       "|        19|       Ava Harris|  2023-05-24|   2023-05-30|Executive|      750.0|\n",
       "|        20| Daniel Rodriguez|  2023-05-25|   2023-05-29|   Deluxe|      550.0|\n",
       "+----------+-----------------+------------+-------------+---------+-----------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select * from itv016269_databases.hotels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c88603eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>total_bookings</th></tr>\n",
       "<tr><td>107</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------------+\n",
       "|total_bookings|\n",
       "+--------------+\n",
       "|           107|\n",
       "+--------------+"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select count(booking_id) as total_bookings from itv016269_databases.hotels \") #Execution time 0.2 secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07267a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>room_type</th><th>total_bookings</th></tr>\n",
       "<tr><td>Executive</td><td>750.0</td></tr>\n",
       "<tr><td>Deluxe</td><td>575.58</td></tr>\n",
       "<tr><td>Standard</td><td>425.0</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+---------+--------------+\n",
       "|room_type|total_bookings|\n",
       "+---------+--------------+\n",
       "|Executive|         750.0|\n",
       "|   Deluxe|        575.58|\n",
       "| Standard|         425.0|\n",
       "+---------+--------------+"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select room_type, round(avg(total_price),2) as total_bookings from itv016269_databases.hotels group by room_type \") #Execution time 0.8 secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36f8e8f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th></th></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"cache lazy table itv016269_databases.hotels \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc502021",
   "metadata": {},
   "source": [
    "# Caching on External Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e2820664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>total_bookings</th></tr>\n",
       "<tr><td>107</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------------+\n",
       "|total_bookings|\n",
       "+--------------+\n",
       "|           107|\n",
       "+--------------+"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select count(booking_id) as total_bookings from itv016269_databases.hotels \") #Execution time 32 msecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a3ab318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>room_type</th><th>total_bookings</th></tr>\n",
       "<tr><td>Executive</td><td>750.0</td></tr>\n",
       "<tr><td>Deluxe</td><td>575.58</td></tr>\n",
       "<tr><td>Standard</td><td>425.0</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+---------+--------------+\n",
       "|room_type|total_bookings|\n",
       "+---------+--------------+\n",
       "|Executive|         750.0|\n",
       "|   Deluxe|        575.58|\n",
       "| Standard|         425.0|\n",
       "+---------+--------------+"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select room_type, round(avg(total_price),2) as total_bookings from itv016269_databases.hotels group by room_type \") #Execution time 0.2 secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b2e293",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 3",
   "language": "python",
   "name": "pyspark3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
